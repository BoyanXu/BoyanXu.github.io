---
layout: post
title: Knowledge Graph, and Search Engine
subtitle: Exploit internet's infinity the intelligent way
date: 2019-05-18T16:00:00.000+00:00
author: Boyan Xu
header-img: ''
catalog: false
tags:
- meditation

---
# Knowledge Graph, and Search Engine

I noticed that the structure of knowledges produced by human being as a whole, looks like a graph, or network. Each knowledge is connected with several "neighbour" knowledges, and therefore have higher probability in appearing together with its neighbour in one's description, narration, explanation, or argument. Therefore the abstract knowledges maintains their graph structure in human's concrete language system, which means related knowledges often appear together with higher probability in a single source of language.

This fact could be pretty instructive for us on how to exploit search engines to shrink distance between you and your target information. The process of googling, is equivalent to finding texts on the internet that are highly related to the keywords you typed in. If your target information is supposed to be availble, searchable, then the only thing that can prevent you from reveicing pleasant searching result is that you failed to accurately describe your target with "community language". By "community language" I mean the way an insider, expert, senior, or anyone who is frequently exposed to your target topic, would describe the same thing as you did. The difference between searching with your own awkwardly organized language and searching with "community language" is obvious with the straightforward reason as we mentioned. If you search with your awkwardly organized language, the search engine will mostly return you with descriptions, narrations, explanaions, or arguments from newbies, novices, or any outsider like you, which are usually shallow, uninspiring and generalized, instead of deep, enlighening, and comprehensive. In another word, searching with "community language", is an indirect way of engaging in online professional discussion on what you are interested in, exactly like auditing some professional seminars in the real world. The way experts articulate ideas on your target information, won't be the end of your exploration, but instead, will be a brand new origin of new linkages, promoting you to further further exploration.

Therefore, the first step we should intentionally perform after googling some raw idea is to recursively "sharpen" our raw language into "community language." That is we should repeatedly update our keywords into those more potentional to link to better searching result. In most cases, as we are not expert at the first search, it's unaviodable to start with awkward keywords. Then what we can generally do is to have an eye on the "community language" appeared in the results from your first search, thinking about what you can learn from those "community language" to refine your keywords. It may take several times to eventualy obtain keywords accurate enough.

Things we search with are usually part of a complex system. Without digging into the interactions between that specific part and the rest, we will easily find our searching result unreadable at all, or the conprehension we built will be extremely vulnerable. A popular intuition towards this issue is that the we will never totally understand the part we are interested without completely understanding the whole system beforehand. This intuition could be true, but might not be practical or operative in the real life. Simply because no one have unlimited time. Usually, our real goal of research on something is not to gain a comprehensive comprehension, but a clear enough comprehension that is enough for us to understand how it interact with the system we are working on.

We can model this issue in the following way: to gain enough understanding of a knowledge A, we have to fisrt undertand a set of its neighbour knowledges S. The probability is that

We can take either BFS (breadth-first-search) or DFS (depth-first-search) approach to